{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 3\n",
    "\n",
    "\n",
    "## 1. Instalar Anaconda\n",
    "\n",
    "Para este laboratorio (sesiones 2.1 y 2.2) usaremos Python y algunas librerías para entrenar clasificadores. La forma más fácil de tener un ambiente de Python con todas las librerías más comunes es instalar Anaconda.\n",
    "\n",
    "Para instalar Anaconda:\n",
    "- Descarga de aquí la versión Python 3.6 de tu plataforma: https://www.continuum.io/downloads\n",
    "- Sigue las instrucciones de instalación en \"How to install ANACONDA\"\n",
    "- Asegúrate de dejar en el PATH el directorio `bin` de anaconda. Puedes probar tu instalación ejecutando `python` en una terminal y verificar que dice algo como `Python 3.6.1 |Anaconda 4.4.0` al principio\n",
    "\n",
    "**Nota:** Anaconda facilita mucho la instalación de las librerías que usaremos en este laboratorio. Instalar las librerías (scikit-learn, jupyter) desde cero puede ser un poco complicado si no estás seguro/a de lo que estás haciendo :P\n",
    "\n",
    "\n",
    "## 2. Jupyter notebook\n",
    "\n",
    "Jupyter notebook es una aplicación Web que permite crear documentos con código Python (similar a los R Notebooks o R Markdown que usamos para los enunciados de los laboratorios pasados). En el próximo laboratorio usaremos un notebook que deberán completar con sus respuestas, y podrán verificar en el mismo si éstas están correctas.\n",
    "\n",
    "Puedes descargar este mismo notebook (.ipynb) y cargarlo localmente ejecutando `jupyter notebook` en la terminal. Procura estar en el directorio que contiene el archivo .ipynb.\n",
    "\n",
    "Por ejemplo:\n",
    "\n",
    "```cd ~/uchile-cc5206/tutoriales/\n",
    "jupyter noteboook\n",
    "```\n",
    "\n",
    "## 3. Cargar librerías\n",
    "\n",
    "Usaremos `scikit-learn` (http://scikit-learn.org) que contiene muchos modelos de machine learning instalados. Si ya instalaste Anaconda, no necesitas instalar nada más.\n",
    "\n",
    "Para el resto del tutorial, asumiremos que estás usando este mismo notebook. Para cargar las librerías, haz click en el siguiente bloque de código, y para ejecutarlo, presiona `Shift+Enter`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Listo!\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "\n",
    "print(\"Listo!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 4. Exploración del Iris Dataset\n",
    "\n",
    "El método `load_iris` permite cargar el Iris dataset, que contiene 150 *instancias* (filas) de 3 *clases* diferentes de flores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4.9,  3. ,  1.4,  0.2],\n",
       "       [ 4.7,  3.2,  1.3,  0.2],\n",
       "       [ 4.6,  3.1,  1.5,  0.2],\n",
       "       [ 5. ,  3.6,  1.4,  0.2],\n",
       "       [ 5.4,  3.9,  1.7,  0.4],\n",
       "       [ 4.6,  3.4,  1.4,  0.3],\n",
       "       [ 5. ,  3.4,  1.5,  0.2],\n",
       "       [ 4.4,  2.9,  1.4,  0.2],\n",
       "       [ 4.9,  3.1,  1.5,  0.1]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris = load_iris()\n",
    "iris.data[1:10]   # presionando TAB después del punto '.' hace que jupyter muestre los campos disponibles de la variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que las primeras 10 filas del dataset contienen ciertos números. Podemos saber los nombres de los *features* (columnas) usando el campo `feature_names`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sepal length (cm)',\n",
       " 'sepal width (cm)',\n",
       " 'petal length (cm)',\n",
       " 'petal width (cm)']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.feature_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las clases de cada fila se encuentran en la variable `target`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0]\n",
      "['setosa' 'versicolor' 'virginica']\n"
     ]
    }
   ],
   "source": [
    "print(iris.target[1:10])\n",
    "print(iris.target_names)   # target == 0 corresponde a setosa, target == 1 a versicolor y target == 2 a virginica"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En general, es buena práctica llamar como `X` a la matriz con features y `y` al vector con las clases:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = iris.data\n",
    "y = iris.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Nuestro primer clasificador\n",
    "\n",
    "Entrenaremos nuestro primer clasificador con el Iris dataset. Para esto, usaremos un árbol de decisión:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            presort=False, random_state=None, splitter='best')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "clf = DecisionTreeClassifier()\n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con el método `fit` entrenamos el clasificador con los datos de `X` y la clase asociada a cada uno, `y`. Para ver qué tan bien fue el entrenamiento, podemos evaluar el clasificador ejecutándolo sobre instancias y verificando que la clase sea la correcta. En `scikit-learn` existe el método `accuracy_score` que computa el Accuracy de la clasificación:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_pred = clf.predict(X)\n",
    "print(\"Accuracy:\", accuracy_score(y, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tuvimos un accuracy del 100% con el clasificador. Sin embargo, **hicimos algo incorrecto**: evaluamos el clasificador con los mismos datos con los cuales lo entrenamos! Al hacer esto, lo que terminamos haciendo fue *aprender del input* y evaluar/testear con el mismo *input*. Esto también se denomina *overfitting*.\n",
    "\n",
    "Para tener un resultado más realista de la clasificación, dividiremos el dataset en dos: un *training set* y un *test set*. Cada uno cumple distintos propósitos. El primero nos permite aprender de ejemplos y ajustar el clasificador de acuerdo a éstos, mientras que el segundo nos permite saber qué tan bien *generalizamos* con el clasificador.\n",
    "\n",
    "En `scikit-learn` existe un método que nos permite hacer esta separación de manera aleatoria y estratificada (es decir, manteniendo la proporción de clases entre las instancias de cada set):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.33, random_state=37, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El método nos retorna cuatro listas, los correspondientes a train y a test. El parámetro `test_size` nos permite regular la fracción de los datos que irán a test. El parámetro `random_state` nos permite fijar la semilla para tener resultados consistentes (genera la misma partición de datos). El parámetro `stratify` recibe un arreglo con la distribución de clases, y el método intenta mantener esa misma distribución en las listas resultantes.\n",
    "\n",
    "Ahora podemos probar nuestro clasificador:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy en test set: 0.98\n"
     ]
    }
   ],
   "source": [
    "clf = DecisionTreeClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "print(\"Accuracy en test set:\", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comentarios Finales**:\n",
    "\n",
    "* Observe detenidamente el código anterior para entender qué estamos haciendo.\n",
    "\n",
    "* Como preparación adicional, repase los conceptos de Accuracy, Precision, Recall y F-score.\n",
    "\n",
    "* En la primera sesión del laboratorio (2.1) veremos más técnicas de evaluación y métricas de desempeño de los clasificadores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
